{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOBXePPTtDy6dA5wnJz5zbv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4O4I4nWMRK5V","executionInfo":{"status":"ok","timestamp":1743511180656,"user_tz":-180,"elapsed":4053,"user":{"displayName":"Sason Zade","userId":"15696081868748133077"}},"outputId":"8b35390c-3830-4064-f694-afab5fa2e122"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandasql in /usr/local/lib/python3.11/dist-packages (0.7.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pandasql) (2.0.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from pandasql) (2.2.2)\n","Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.11/dist-packages (from pandasql) (2.0.40)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->pandasql) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->pandasql) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->pandasql) (2025.2)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy->pandasql) (3.1.1)\n","Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy->pandasql) (4.13.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->pandasql) (1.17.0)\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","\n","Cleaned dataset successfully exported to: /content/drive/My Drive/Data_Analyst/Portfolio_Projects/Projects/SQL/Layoffs_Dataset_After_Cleaning.xlsx\n"]}],"source":["# Step 1: Install the required package\n","# pandasql is useful for running SQL queries on Pandas DataFrames, ensuring smooth data manipulation.\n","!pip install pandasql\n","\n","# Step 2: Mount Google Drive\n","# This step ensures that we can access files stored in Google Drive.\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Step 3: Load the CSV file into a Pandas DataFrame\n","import pandas as pd\n","import sqlite3  # SQLite will be used for executing SQL queries\n","\n","# Define the path to the raw data file\n","file_path = '/content/drive/My Drive/Data_Analyst/Portfolio_Projects/Projects/SQL/Layoffs_Dataset_for_Data_Cleaning.csv'\n","\n","# Read the CSV file into a Pandas DataFrame\n","df = pd.read_csv(file_path)\n","\n","# Set Pandas display options to show more rows and all columns for better visibility\n","pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', None)\n","\n","# Step 4: Create an in-memory SQLite database\n","# This allows us to execute SQL queries as if working with a relational database.\n","conn = sqlite3.connect(\":memory:\")\n","\n","# Load the DataFrame into an SQLite table named 'layoffs'\n","df.to_sql(\"layoffs\", conn, index=False, if_exists=\"replace\")\n","\n","# Step 5: Create layoffs_staging table\n","# The layoffs_staging table will hold a copy of the original data for cleaning.\n","query_create_table = \"CREATE TABLE layoffs_staging AS SELECT * FROM layoffs WHERE 1=0;\"\n","conn.execute(query_create_table)\n","\n","# Step 6: Insert data into layoffs_staging\n","query_insert = \"INSERT INTO layoffs_staging SELECT * FROM layoffs;\"\n","conn.execute(query_insert)\n","\n","# Step 7: Add a new column `row_num` to identify duplicate rows\n","conn.execute(\"ALTER TABLE layoffs_staging ADD COLUMN row_num INT;\")\n","\n","# Step 8: Create layoffs_staging2 table\n","# This table will store a cleaned version of layoffs_staging while tracking duplicate records.\n","query_create_table2 = \"\"\"\n","CREATE TABLE layoffs_staging2 (\n","    company TEXT,\n","    location TEXT,\n","    industry TEXT,\n","    total_laid_off INT,\n","    percentage_laid_off TEXT,\n","    date TEXT,\n","    stage TEXT,\n","    country TEXT,\n","    funds_raised INT,\n","    row_num INT\n",");\n","\"\"\"\n","conn.execute(query_create_table2)\n","\n","# Step 9: Insert data into layoffs_staging2 while assigning a row number\n","# The ROW_NUMBER() function helps in identifying duplicate records by assigning unique row numbers within each duplicate group.\n","query_insert_into_staging2 = \"\"\"\n","INSERT INTO layoffs_staging2\n","(company, location, industry, total_laid_off, percentage_laid_off, date, stage, country, funds_raised, row_num)\n","SELECT company, location, industry, total_laid_off, percentage_laid_off, date, stage, country, funds_raised,\n","       ROW_NUMBER() OVER (\n","           PARTITION BY company, location, industry, total_laid_off, percentage_laid_off, date, stage, country, funds_raised\n","       ) AS row_num\n","FROM layoffs_staging;\n","\"\"\"\n","conn.execute(query_insert_into_staging2)\n","\n","# Step 10: Remove duplicate records\n","# We delete rows where row_num >= 2, keeping only the first occurrence of each duplicate.\n","conn.execute(\"DELETE FROM layoffs_staging2 WHERE row_num >= 2;\")\n","\n","# Step 11: Standardize missing industry names by replacing empty strings with NULL\n","conn.execute(\"UPDATE layoffs_staging2 SET industry = NULL WHERE industry = '';\")\n","\n","# **Fix for SQLite Compatibility: Updating NULL Industries**\n","# SQLite does not support JOINs in UPDATE statements, so we use a temporary table.\n","\n","# Step 12: Create a temporary table mapping companies to their industry\n","query_create_temp_table = \"\"\"\n","CREATE TABLE temp_industry_update AS\n","SELECT company, MAX(industry) AS industry\n","FROM layoffs_staging2\n","WHERE industry IS NOT NULL\n","GROUP BY company;\n","\"\"\"\n","conn.execute(query_create_temp_table)\n","\n","# Step 13: Update layoffs_staging2 industries based on the temporary table\n","query_update_industry = \"\"\"\n","UPDATE layoffs_staging2\n","SET industry = (SELECT temp_industry_update.industry\n","                FROM temp_industry_update\n","                WHERE layoffs_staging2.company = temp_industry_update.company)\n","WHERE industry IS NULL;\n","\"\"\"\n","conn.execute(query_update_industry)\n","\n","# Step 14: Remove the temporary table (clean up)\n","conn.execute(\"DROP TABLE temp_industry_update;\")\n","\n","# Step 15: Standardize variations in industry names\n","conn.execute(\"\"\"\n","UPDATE layoffs_staging2\n","SET industry = 'Crypto'\n","WHERE industry IN ('Crypto Currency', 'CryptoCurrency');\n","\"\"\")\n","\n","# Step 16: Standardize country names\n","# The issue: Some country names have a trailing period (e.g., \"United States.\" instead of \"United States\").\n","# The solution: Use REPLACE() to remove trailing periods.\n","conn.execute(\"UPDATE layoffs_staging2 SET country = REPLACE(country, '.', '');\")\n","\n","# Step 17: Convert date column to proper format\n","# The `date` column is currently stored as a text field. We update it to use the correct date format (YYYY-MM-DD).\n","conn.execute(\"UPDATE layoffs_staging2 SET date = strftime('%Y-%m-%d', date);\")\n","\n","# Step 18: Remove records with missing essential data\n","# If both `total_laid_off` and `percentage_laid_off` are NULL, the data is unusable, so we delete such records.\n","conn.execute(\"DELETE FROM layoffs_staging2 WHERE total_laid_off IS NULL AND percentage_laid_off IS NULL;\")\n","\n","# Step 19: Drop the `row_num` column\n","# The `row_num` column was useful for removing duplicates, but it is no longer needed.\n","query_drop_row_num = \"\"\"\n","CREATE TABLE layoffs_staging2_no_row_num AS\n","SELECT company, location, industry, total_laid_off, percentage_laid_off, date, stage, country, funds_raised\n","FROM layoffs_staging2;\n","\"\"\"\n","conn.execute(query_drop_row_num)\n","\n","# Step 20: Export the cleaned data to an Excel file\n","query_export_cleaned_data = \"SELECT * FROM layoffs_staging2_no_row_num;\"\n","df_cleaned = pd.read_sql(query_export_cleaned_data, conn)\n","\n","# Define export file path\n","export_path = '/content/drive/My Drive/Data_Analyst/Portfolio_Projects/Projects/SQL/Layoffs_Dataset_After_Cleaning.xlsx'\n","\n","# Export the cleaned dataset to an Excel file\n","df_cleaned.to_excel(export_path, index=False)\n","\n","print(f\"\\nCleaned dataset successfully exported to: {export_path}\")\n","\n","# Step 21: Close the SQLite connection\n","# This ensures that resources are released after execution.\n","conn.close()\n"]}]}