{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNVe7sPo0AoHwTc9NXZ0S7r"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4O4I4nWMRK5V","executionInfo":{"status":"ok","timestamp":1743505239978,"user_tz":-180,"elapsed":7580,"user":{"displayName":"Sason Zade","userId":"15696081868748133077"}},"outputId":"8fecdba2-ac09-48de-cb79-9155bd31694a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandasql in /usr/local/lib/python3.11/dist-packages (0.7.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pandasql) (2.0.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from pandasql) (2.2.2)\n","Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.11/dist-packages (from pandasql) (2.0.40)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->pandasql) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->pandasql) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->pandasql) (2025.2)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy->pandasql) (3.1.1)\n","Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy->pandasql) (4.13.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->pandasql) (1.17.0)\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","\n","Cleaned dataset successfully exported to: /content/drive/My Drive/Data_Analyst/Portfolio_Projects/Projects/SQL/Layoffs_Dataset_After_Cleaning.xlsx\n"]}],"source":["# Step 1: Install missing package\n","!pip install pandasql\n","\n","# Step 2: Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Step 3: Load the CSV file into a Pandas DataFrame\n","import pandas as pd\n","import sqlite3\n","\n","file_path = '/content/drive/My Drive/Data_Analyst/Portfolio_Projects/Projects/SQL/Layoffs_Dataset_for_Data_Cleaning.csv'\n","df = pd.read_csv(file_path)\n","\n","# Ensure Pandas displays a maximum of 500 rows\n","pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', None)\n","\n","# Step 4: Create an SQLite in-memory database and load the DataFrame\n","conn = sqlite3.connect(\":memory:\")\n","df.to_sql(\"layoffs\", conn, index=False, if_exists=\"replace\")\n","\n","# Step 5: Create layoffs_staging table\n","query_create_table = \"CREATE TABLE layoffs_staging AS SELECT * FROM layoffs WHERE 1=0;\"\n","conn.execute(query_create_table)\n","\n","# Step 6: Insert data into layoffs_staging\n","query_insert = \"INSERT INTO layoffs_staging SELECT * FROM layoffs;\"\n","conn.execute(query_insert)\n","\n","# Step 7: Add row_num column\n","conn.execute(\"ALTER TABLE layoffs_staging ADD COLUMN row_num INT;\")\n","\n","# Step 8: Create layoffs_staging2 table\n","query_create_table2 = \"\"\"\n","CREATE TABLE layoffs_staging2 (\n","    company TEXT,\n","    location TEXT,\n","    industry TEXT,\n","    total_laid_off INT,\n","    percentage_laid_off TEXT,\n","    date TEXT,\n","    stage TEXT,\n","    country TEXT,\n","    funds_raised INT,\n","    row_num INT\n",");\n","\"\"\"\n","conn.execute(query_create_table2)\n","\n","# Step 9: Insert data into layoffs_staging2 with row numbers\n","query_insert_into_staging2 = \"\"\"\n","INSERT INTO layoffs_staging2\n","(company, location, industry, total_laid_off, percentage_laid_off, date, stage, country, funds_raised, row_num)\n","SELECT company, location, industry, total_laid_off, percentage_laid_off, date, stage, country, funds_raised,\n","       ROW_NUMBER() OVER (\n","           PARTITION BY company, location, industry, total_laid_off, percentage_laid_off, date, stage, country, funds_raised\n","       ) AS row_num\n","FROM layoffs_staging;\n","\"\"\"\n","conn.execute(query_insert_into_staging2)\n","\n","# Step 10: Remove duplicates (keep only row_num = 1)\n","conn.execute(\"DELETE FROM layoffs_staging2 WHERE row_num >= 2;\")\n","\n","# Step 11: Standardize industry names\n","conn.execute(\"UPDATE layoffs_staging2 SET industry = NULL WHERE industry = '';\")\n","\n","# **Fix for SQLite Compatibility: Updating NULL Industries**\n","# Step 1: Create a temporary table with company-wise industry data (ignoring NULLs)\n","query_create_temp_table = \"\"\"\n","CREATE TABLE temp_industry_update AS\n","SELECT company, MAX(industry) AS industry\n","FROM layoffs_staging2\n","WHERE industry IS NOT NULL\n","GROUP BY company;\n","\"\"\"\n","conn.execute(query_create_temp_table)\n","\n","# Step 2: Update layoffs_staging2 using the temporary table\n","query_update_industry = \"\"\"\n","UPDATE layoffs_staging2\n","SET industry = (SELECT temp_industry_update.industry\n","                FROM temp_industry_update\n","                WHERE layoffs_staging2.company = temp_industry_update.company)\n","WHERE industry IS NULL;\n","\"\"\"\n","conn.execute(query_update_industry)\n","\n","# Step 3: Drop the temporary table (clean up)\n","conn.execute(\"DROP TABLE temp_industry_update;\")\n","\n","# **Continue with standardization**\n","conn.execute(\"\"\"\n","UPDATE layoffs_staging2\n","SET industry = 'Crypto'\n","WHERE industry IN ('Crypto Currency', 'CryptoCurrency');\n","\"\"\")\n","\n","# Step 12: Standardize country names (fix trailing periods)\n","conn.execute(\"UPDATE layoffs_staging2 SET country = REPLACE(country, '.', '');\")\n","\n","# Step 13: Convert date column to proper format\n","conn.execute(\"UPDATE layoffs_staging2 SET date = strftime('%Y-%m-%d', date);\")\n","\n","# Step 14: Remove records where both total_laid_off and percentage_laid_off are NULL\n","conn.execute(\"DELETE FROM layoffs_staging2 WHERE total_laid_off IS NULL AND percentage_laid_off IS NULL;\")\n","\n","# Step 15: Drop row_num column\n","query_drop_row_num = \"\"\"\n","CREATE TABLE layoffs_staging2_no_row_num AS\n","SELECT company, location, industry, total_laid_off, percentage_laid_off, date, stage, country, funds_raised\n","FROM layoffs_staging2;\n","\"\"\"\n","conn.execute(query_drop_row_num)\n","\n","# Step 16: Export cleaned data to an Excel file\n","query_export_cleaned_data = \"SELECT * FROM layoffs_staging2_no_row_num;\"\n","df_cleaned = pd.read_sql(query_export_cleaned_data, conn)\n","\n","# Define export file path\n","export_path = '/content/drive/My Drive/Data_Analyst/Portfolio_Projects/Projects/SQL/Layoffs_Dataset_After_Cleaning.xlsx'\n","\n","# Export to Excel\n","df_cleaned.to_excel(export_path, index=False)\n","\n","print(f\"\\nCleaned dataset successfully exported to: {export_path}\")\n","\n","# Close the SQLite connection\n","conn.close()\n"]}]}