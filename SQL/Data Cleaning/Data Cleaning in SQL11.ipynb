{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO3CIuECHO39nflZmNArnU7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":695},"id":"BkiHbCMobn3g","executionInfo":{"status":"ok","timestamp":1744116858624,"user_tz":-180,"elapsed":5304,"user":{"displayName":"Sason Zade","userId":"15696081868748133077"}},"outputId":"d939be46-defe-4884-a869-f15c2e5c71f7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","All packages installed successfully\n","\n","==================================================\n"," DATA CLEANING COMPLETE\n","==================================================\n"," Final dataset shape: 1739 rows × 13 columns\n"," Date range: 2023-01-01 to 2025-03-19\n"," Companies analyzed: 1383\n"," Countries represented: 47\n"," Total employees laid off: 440,074\n"," Files saved:\n","   - Excel: Layoffs_Dataset_Cleaned_20250408_125411.xlsx\n","   - CSV: Layoffs_Dataset_Cleaned_20250408_125411.csv\n","==================================================\n","\n"," TOP 5 INDUSTRIES BY LAYOFFS:\n","   1. other: 56,815 employees\n","   2. hardware: 55,823 employees\n","   3. consumer_goods: 45,777 employees\n","   4. retail: 43,067 employees\n","   5. transportation: 32,395 employees\n"]},{"output_type":"execute_result","data":{"text/plain":["       company                   location        industry  total_laid_off  \\\n","0       Micron                  ['Boise']        hardware          4800.0   \n","1       Amdocs              ['St. Louis']         support           700.0   \n","2    Bytedance   ['Shanghai', 'Non-U.S.']  consumer_goods             NaN   \n","3      Harappa  ['New Delhi', 'Non-U.S.']       education            60.0   \n","4  Pegasystems                 ['Boston']              hr           245.0   \n","\n","   percentage_laid_off       date  year  month  quarter     stage  \\\n","0                 10.0 2023-01-01  2023      1        1  Post-IPO   \n","1                  3.0 2023-01-02  2023      1        1  Post-IPO   \n","2                 10.0 2023-01-03  2023      1        1   Unknown   \n","3                 30.0 2023-01-03  2023      1        1  Acquired   \n","4                  4.0 2023-01-03  2023      1        1  Post-IPO   \n","\n","         country  funds_raised layoff_severity  \n","0  United States          50.0             Low  \n","1  United States           NaN        Very Low  \n","2          China        9400.0             Low  \n","3          India           NaN            High  \n","4  United States           NaN        Very Low  "],"text/html":["\n","  <div id=\"df-0c756a70-9377-4f08-b612-1ce5329e55f4\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>company</th>\n","      <th>location</th>\n","      <th>industry</th>\n","      <th>total_laid_off</th>\n","      <th>percentage_laid_off</th>\n","      <th>date</th>\n","      <th>year</th>\n","      <th>month</th>\n","      <th>quarter</th>\n","      <th>stage</th>\n","      <th>country</th>\n","      <th>funds_raised</th>\n","      <th>layoff_severity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Micron</td>\n","      <td>['Boise']</td>\n","      <td>hardware</td>\n","      <td>4800.0</td>\n","      <td>10.0</td>\n","      <td>2023-01-01</td>\n","      <td>2023</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Post-IPO</td>\n","      <td>United States</td>\n","      <td>50.0</td>\n","      <td>Low</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Amdocs</td>\n","      <td>['St. Louis']</td>\n","      <td>support</td>\n","      <td>700.0</td>\n","      <td>3.0</td>\n","      <td>2023-01-02</td>\n","      <td>2023</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Post-IPO</td>\n","      <td>United States</td>\n","      <td>NaN</td>\n","      <td>Very Low</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Bytedance</td>\n","      <td>['Shanghai', 'Non-U.S.']</td>\n","      <td>consumer_goods</td>\n","      <td>NaN</td>\n","      <td>10.0</td>\n","      <td>2023-01-03</td>\n","      <td>2023</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Unknown</td>\n","      <td>China</td>\n","      <td>9400.0</td>\n","      <td>Low</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Harappa</td>\n","      <td>['New Delhi', 'Non-U.S.']</td>\n","      <td>education</td>\n","      <td>60.0</td>\n","      <td>30.0</td>\n","      <td>2023-01-03</td>\n","      <td>2023</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Acquired</td>\n","      <td>India</td>\n","      <td>NaN</td>\n","      <td>High</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Pegasystems</td>\n","      <td>['Boston']</td>\n","      <td>hr</td>\n","      <td>245.0</td>\n","      <td>4.0</td>\n","      <td>2023-01-03</td>\n","      <td>2023</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Post-IPO</td>\n","      <td>United States</td>\n","      <td>NaN</td>\n","      <td>Very Low</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c756a70-9377-4f08-b612-1ce5329e55f4')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-0c756a70-9377-4f08-b612-1ce5329e55f4 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-0c756a70-9377-4f08-b612-1ce5329e55f4');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-a89666c1-51f8-4542-a191-170cf1d8e195\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a89666c1-51f8-4542-a191-170cf1d8e195')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-a89666c1-51f8-4542-a191-170cf1d8e195 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_final","summary":"{\n  \"name\": \"df_final\",\n  \"rows\": 1739,\n  \"fields\": [\n    {\n      \"column\": \"company\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1383,\n        \"samples\": [\n          \"Flex\",\n          \"Exterro\",\n          \"Innovid\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"location\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 192,\n        \"samples\": [\n          \"['Santiago', 'Non-U.S.']\",\n          \"['Lexington']\",\n          \"['Jakarta', 'Non-U.S.']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"industry\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"recruiting\",\n          \"transportation\",\n          \"construction\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_laid_off\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1083.0065447242089,\n        \"min\": 5.0,\n        \"max\": 15000.0,\n        \"num_unique_values\": 287,\n        \"samples\": [\n          30.0,\n          14000.0,\n          32.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"percentage_laid_off\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15.299134472529472,\n        \"min\": 1.0,\n        \"max\": 92.0,\n        \"num_unique_values\": 60,\n        \"samples\": [\n          10.0,\n          20.0,\n          22.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2023-01-01 00:00:00\",\n        \"max\": \"2025-03-19 00:00:00\",\n        \"num_unique_values\": 541,\n        \"samples\": [\n          \"2023-10-19 00:00:00\",\n          \"2023-03-31 00:00:00\",\n          \"2024-04-18 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2023,\n        \"max\": 2025,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2023,\n          2024,\n          2025\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"month\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 12,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          11,\n          10,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"quarter\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          4,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stage\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"Post-IPO\",\n          \"Unknown\",\n          \"Series A\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"country\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 47,\n        \"samples\": [\n          \"Austria\",\n          \"Lithuania\",\n          \"Poland\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"funds_raised\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2250.677294315009,\n        \"min\": 1.0,\n        \"max\": 27200.0,\n        \"num_unique_values\": 546,\n        \"samples\": [\n          337.0,\n          21.0,\n          529.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"layoff_severity\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Very Low\",\n          \"Very High\",\n          \"High\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":2}],"source":["# STEP 1: Mount Google Drive and configure environment\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# STEP 2: Install and import required libraries with error handling\n","try:\n","    !pip install -q pandas sqlalchemy openpyxl tqdm\n","    print(\"All packages installed successfully\")\n","except Exception as e:\n","    print(f\"Issue with package installation: {e}\")\n","\n","import pandas as pd\n","import numpy as np\n","from sqlalchemy import create_engine, text\n","import os\n","from datetime import datetime\n","from tqdm.notebook import tqdm\n","import logging\n","\n","# Configure logging\n","logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n","logger = logging.getLogger('layoffs_cleaning')\n","\n","# STEP 3: Define paths with improved error handling\n","try:\n","    input_path = '/content/drive/My Drive/Data_Analyst/Portfolio_Projects/Projects/SQL/Layoffs_Dataset_for_Data_Cleaning.csv'\n","    output_dir = '/content/drive/My Drive/Data_Analyst/Portfolio_Projects/Projects/SQL'\n","\n","    # Create timestamped output filename for versioning\n","    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","    output_excel = os.path.join(output_dir, f'Layoffs_Dataset_Cleaned_{timestamp}.xlsx')\n","    output_csv = os.path.join(output_dir, f'Layoffs_Dataset_Cleaned_{timestamp}.csv')\n","\n","    # Check if input file exists\n","    if not os.path.exists(input_path):\n","        raise FileNotFoundError(f\"Input file not found: {input_path}\")\n","\n","    logger.info(f\"Input file confirmed: {input_path}\")\n","except Exception as e:\n","    logger.error(f\"Path setup error: {e}\")\n","    raise\n","\n","# STEP 4: Load initial data to get column names and structure\n","try:\n","    logger.info(\"Loading raw data sample...\")\n","    # Just load a small sample to get schema\n","    df_sample = pd.read_csv(input_path, nrows=5)\n","    logger.info(f\"Raw data columns: {', '.join(df_sample.columns)}\")\n","except Exception as e:\n","    logger.error(f\"Data loading error: {e}\")\n","    raise\n","\n","# STEP 5: Create SQL engine and load data directly using SQL\n","try:\n","    logger.info(\"Creating SQL engine...\")\n","    engine = create_engine('sqlite://', echo=False)\n","\n","    # Create table structure first\n","    with engine.begin() as conn:\n","        conn.execute(text(\"\"\"\n","            CREATE TABLE layoffs_raw (\n","                company TEXT,\n","                location TEXT,\n","                industry TEXT,\n","                total_laid_off TEXT,\n","                percentage_laid_off TEXT,\n","                date TEXT,\n","                stage TEXT,\n","                country TEXT,\n","                funds_raised TEXT\n","            )\n","        \"\"\"))\n","\n","    # Load data in chunks using SQL COPY or equivalent\n","    logger.info(\"Loading data into SQLite...\")\n","    chunksize = 10000\n","\n","    # Using simple progressbar instead of tqdm.notebook to avoid widget state issue\n","    chunks = pd.read_csv(input_path, chunksize=chunksize)\n","    chunk_count = 0\n","    for chunk in chunks:\n","        chunk.to_sql('layoffs_raw', con=engine, if_exists='append', index=False)\n","        chunk_count += 1\n","        if chunk_count % 5 == 0:\n","            logger.info(f\"Processed {chunk_count * chunksize} rows...\")\n","\n","    # Get raw counts for reporting\n","    with engine.connect() as conn:\n","        raw_count = conn.execute(text(\"SELECT COUNT(*) FROM layoffs_raw\")).scalar()\n","\n","    logger.info(f\"Raw data loaded: {raw_count} rows\")\n","\n","    # Get missing values using SQL\n","    with engine.connect() as conn:\n","        missing_columns = conn.execute(text(\"\"\"\n","            SELECT\n","                SUM(CASE WHEN company IS NULL OR company = '' THEN 1 ELSE 0 END) AS company_missing,\n","                SUM(CASE WHEN location IS NULL OR location = '' THEN 1 ELSE 0 END) AS location_missing,\n","                SUM(CASE WHEN industry IS NULL OR industry = '' THEN 1 ELSE 0 END) AS industry_missing,\n","                SUM(CASE WHEN total_laid_off IS NULL OR total_laid_off = '' THEN 1 ELSE 0 END) AS total_laid_off_missing,\n","                SUM(CASE WHEN percentage_laid_off IS NULL OR percentage_laid_off = '' THEN 1 ELSE 0 END) AS percentage_laid_off_missing,\n","                SUM(CASE WHEN date IS NULL OR date = '' THEN 1 ELSE 0 END) AS date_missing,\n","                SUM(CASE WHEN stage IS NULL OR stage = '' THEN 1 ELSE 0 END) AS stage_missing,\n","                SUM(CASE WHEN country IS NULL OR country = '' THEN 1 ELSE 0 END) AS country_missing,\n","                SUM(CASE WHEN funds_raised IS NULL OR funds_raised = '' THEN 1 ELSE 0 END) AS funds_raised_missing\n","            FROM layoffs_raw\n","        \"\"\")).fetchone()\n","\n","    missing_stats = {col: val for col, val in zip(df_sample.columns, missing_columns)}\n","    for col, val in missing_stats.items():\n","        logger.info(f\"Column '{col}': {val} missing values ({val/raw_count*100:.2f}%)\")\n","\n","    # Find duplicates using SQL - FIXED: SQLite doesn't support COUNT(DISTINCT multiple columns)\n","    with engine.connect() as conn:\n","        # Alternative approach: Count total rows vs unique combinations using GROUP BY\n","        total_rows = conn.execute(text(\"SELECT COUNT(*) FROM layoffs_raw\")).scalar()\n","\n","        # Count unique combinations\n","        unique_rows = conn.execute(text(\"\"\"\n","            SELECT COUNT(*) FROM (\n","                SELECT company, location, industry, total_laid_off,\n","                       percentage_laid_off, date, stage, country, funds_raised\n","                FROM layoffs_raw\n","                GROUP BY company, location, industry, total_laid_off,\n","                         percentage_laid_off, date, stage, country, funds_raised\n","            )\n","        \"\"\")).scalar()\n","\n","        dup_count = total_rows - unique_rows\n","\n","    logger.info(f\"Found {dup_count} potential duplicate rows ({dup_count/raw_count*100:.2f}%)\")\n","\n","except Exception as e:\n","    logger.error(f\"SQL engine error: {e}\")\n","    raise\n","\n","# STEP 6: Comprehensive SQL data cleaning pipeline\n","try:\n","    logger.info(\"Starting SQL cleaning process...\")\n","    with engine.begin() as conn:\n","        # Step 6.1: Create a table with basic cleaning and type conversions\n","        logger.info(\"Creating initial clean table...\")\n","        conn.execute(text(\"\"\"\n","            CREATE TABLE layoffs_base AS\n","            SELECT\n","                TRIM(company) AS company,\n","                TRIM(location) AS location,\n","                TRIM(LOWER(REPLACE(REPLACE(industry, ' ', '_'), '-', '_'))) AS industry,\n","                CASE\n","                    WHEN total_laid_off = '' THEN NULL\n","                    ELSE CAST(total_laid_off AS INTEGER)\n","                END AS total_laid_off,\n","                CASE\n","                    WHEN percentage_laid_off = '' THEN NULL\n","                    WHEN percentage_laid_off LIKE '%\\%%' THEN\n","                        CAST(REPLACE(percentage_laid_off, '%', '') AS REAL)\n","                    WHEN CAST(percentage_laid_off AS REAL) > 1.0 AND CAST(percentage_laid_off AS REAL) <= 100 THEN\n","                        CAST(percentage_laid_off AS REAL)\n","                    WHEN CAST(percentage_laid_off AS REAL) > 0 AND CAST(percentage_laid_off AS REAL) < 1.0 THEN\n","                        CAST(percentage_laid_off AS REAL) * 100\n","                    ELSE CAST(percentage_laid_off AS REAL)\n","                END AS percentage_laid_off,\n","                date,\n","                TRIM(stage) AS stage,\n","                TRIM(country) AS country,\n","                CASE\n","                    WHEN funds_raised = '' THEN NULL\n","                    ELSE CAST(funds_raised AS REAL)\n","                END AS funds_raised\n","            FROM layoffs_raw\n","            WHERE NOT (\n","                (company IS NULL OR company = '') AND\n","                (location IS NULL OR location = '') AND\n","                (industry IS NULL OR industry = '')\n","            )\n","        \"\"\"))\n","\n","        # Step 6.2: Create a table with deduplicated records\n","        logger.info(\"Removing duplicates...\")\n","        conn.execute(text(\"\"\"\n","            CREATE TABLE layoffs_deduped AS\n","            WITH numbered_rows AS (\n","                SELECT *,\n","                    ROW_NUMBER() OVER (\n","                        PARTITION BY company, location, industry, total_laid_off,\n","                                    percentage_laid_off, date, stage, country, funds_raised\n","                        ORDER BY company\n","                    ) AS rn\n","                FROM layoffs_base\n","            )\n","            SELECT\n","                company, location, industry, total_laid_off, percentage_laid_off,\n","                date, stage, country, funds_raised\n","            FROM numbered_rows\n","            WHERE rn = 1\n","        \"\"\"))\n","\n","        # Step 6.3: Create a table with standardized values\n","        logger.info(\"Standardizing values...\")\n","        conn.execute(text(\"\"\"\n","            CREATE TABLE layoffs_normalized AS\n","            SELECT\n","                CASE\n","                    WHEN company = 'Intel' THEN 'Intel Corporation'\n","                    WHEN company = 'Amazon' THEN 'Amazon.com Inc.'\n","                    WHEN company = 'Meta' THEN 'Meta Platforms Inc.'\n","                    WHEN company = 'Google' THEN 'Google LLC'\n","                    ELSE company\n","                END AS company,\n","\n","                location,\n","\n","                CASE\n","                    WHEN industry IN ('cryptocurrency', 'crypto_currency', 'crypto') THEN 'crypto'\n","                    WHEN industry IN ('consumer', 'consumer_retail', 'consumer_services') THEN 'consumer_goods'\n","                    WHEN industry IN ('healthcare', 'health', 'medical') THEN 'health_care'\n","                    WHEN industry IN ('finance', 'financial') THEN 'financial_services'\n","                    WHEN industry IN ('transport', 'transportation') THEN 'transportation'\n","                    WHEN industry IN ('realestate', 'real_estate', 'property') THEN 'real_estate'\n","                    WHEN industry IN ('ai', 'artificial_intelligence', 'machine_learning') THEN 'artificial_intelligence'\n","                    WHEN industry IN ('saas', 'software_as_a_service') THEN 'saas'\n","                    ELSE industry\n","                END AS industry,\n","\n","                total_laid_off,\n","                percentage_laid_off,\n","\n","                -- Validate date format\n","                CASE\n","                    WHEN date IS NULL OR date = '' THEN NULL\n","                    WHEN date LIKE '____-__-__' THEN date  -- Already YYYY-MM-DD\n","                    -- Add more date format conversions as needed\n","                    ELSE date\n","                END AS date,\n","\n","                CASE\n","                    WHEN stage IS NULL OR stage = '' THEN 'unknown'\n","                    WHEN stage IN ('series c-d+', 'series c-d', 'series c-d plus', 'c-d') THEN 'series c-d'\n","                    WHEN stage IN ('private', 'privately held') THEN 'private equity'\n","                    WHEN stage IN ('series a-b', 'series a-b+', 'a-b') THEN 'series a-b'\n","                    WHEN stage = 'ipo' THEN 'public'\n","                    ELSE stage\n","                END AS stage,\n","\n","                CASE\n","                    WHEN country IS NULL OR country = '' THEN 'unknown'\n","                    WHEN country IN ('united states', 'usa', 'us', 'u.s.', 'u.s.a.') THEN 'USA'\n","                    WHEN country IN ('united kingdom', 'uk', 'u.k.', 'britain', 'great britain') THEN 'UK'\n","                    WHEN country IN ('uae', 'united arab emirates') THEN 'UAE'\n","                    -- SQLite doesn't have INITCAP, so handle common countries\n","                    WHEN LOWER(country) = 'canada' THEN 'Canada'\n","                    WHEN LOWER(country) = 'germany' THEN 'Germany'\n","                    WHEN LOWER(country) = 'france' THEN 'France'\n","                    WHEN LOWER(country) = 'india' THEN 'India'\n","                    WHEN LOWER(country) = 'china' THEN 'China'\n","                    WHEN LOWER(country) = 'australia' THEN 'Australia'\n","                    WHEN LOWER(country) = 'japan' THEN 'Japan'\n","                    ELSE country\n","                END AS country,\n","\n","                funds_raised\n","            FROM layoffs_deduped\n","        \"\"\"))\n","\n","        # Step 6.4: Create final table with additional filters and validations\n","        logger.info(\"Creating final cleaned table...\")\n","        conn.execute(text(\"\"\"\n","            CREATE TABLE layoffs_cleaned AS\n","            SELECT *\n","            FROM layoffs_normalized\n","            WHERE (company IS NOT NULL AND company != '')\n","              AND (date IS NOT NULL AND date != '')\n","              AND NOT (total_laid_off IS NULL AND percentage_laid_off IS NULL)\n","        \"\"\"))\n","\n","        # Step 6.5: Add derived columns using SQL\n","        logger.info(\"Adding derived columns...\")\n","        conn.execute(text(\"\"\"\n","            CREATE TABLE layoffs_final AS\n","            SELECT\n","                company,\n","                location,\n","                industry,\n","                total_laid_off,\n","                percentage_laid_off,\n","                date,\n","                -- Extract year, month, quarter using SQLite functions\n","                CAST(SUBSTR(date, 1, 4) AS INTEGER) AS year,\n","                CAST(SUBSTR(date, 6, 2) AS INTEGER) AS month,\n","                CASE\n","                    WHEN CAST(SUBSTR(date, 6, 2) AS INTEGER) BETWEEN 1 AND 3 THEN 1\n","                    WHEN CAST(SUBSTR(date, 6, 2) AS INTEGER) BETWEEN 4 AND 6 THEN 2\n","                    WHEN CAST(SUBSTR(date, 6, 2) AS INTEGER) BETWEEN 7 AND 9 THEN 3\n","                    WHEN CAST(SUBSTR(date, 6, 2) AS INTEGER) BETWEEN 10 AND 12 THEN 4\n","                    ELSE NULL\n","                END AS quarter,\n","                stage,\n","                country,\n","                funds_raised,\n","                -- Add layoff severity category\n","                CASE\n","                    WHEN percentage_laid_off <= 5 THEN 'Very Low'\n","                    WHEN percentage_laid_off <= 10 THEN 'Low'\n","                    WHEN percentage_laid_off <= 25 THEN 'Medium'\n","                    WHEN percentage_laid_off <= 50 THEN 'High'\n","                    ELSE 'Very High'\n","                END AS layoff_severity\n","            FROM layoffs_cleaned\n","            ORDER BY date\n","        \"\"\"))\n","\n","        # Step 6.6: Create summary statistics table for reporting\n","        logger.info(\"Creating summary statistics table...\")\n","        conn.execute(text(\"\"\"\n","            CREATE TABLE layoffs_summary AS\n","            SELECT\n","                COUNT(DISTINCT company) AS total_companies,\n","                COUNT(DISTINCT industry) AS total_industries,\n","                COUNT(DISTINCT country) AS total_countries,\n","                MIN(date) AS earliest_date,\n","                MAX(date) AS latest_date,\n","                SUM(total_laid_off) AS total_employees_laid_off,\n","                AVG(percentage_laid_off) AS avg_percentage_laid_off,\n","                MAX(percentage_laid_off) AS max_percentage_laid_off,\n","                SUM(funds_raised) AS total_funds_raised,\n","                COUNT(*) AS total_layoff_events,\n","                (SELECT COUNT(*) FROM layoffs_raw) AS original_row_count\n","            FROM layoffs_final\n","        \"\"\"))\n","\n","        # Step 6.7: Create industry summary table\n","        logger.info(\"Creating industry summary table...\")\n","        conn.execute(text(\"\"\"\n","            CREATE TABLE industry_summary AS\n","            SELECT\n","                industry,\n","                COUNT(*) AS layoff_events,\n","                SUM(total_laid_off) AS total_laid_off,\n","                AVG(percentage_laid_off) AS avg_percentage_laid_off,\n","                COUNT(DISTINCT company) AS companies_affected\n","            FROM layoffs_final\n","            WHERE industry IS NOT NULL AND industry != ''\n","            GROUP BY industry\n","            ORDER BY total_laid_off DESC\n","        \"\"\"))\n","\n","        # Step 6.8: Create country summary table\n","        logger.info(\"Creating country summary table...\")\n","        conn.execute(text(\"\"\"\n","            CREATE TABLE country_summary AS\n","            SELECT\n","                country,\n","                COUNT(*) AS layoff_events,\n","                SUM(total_laid_off) AS total_laid_off,\n","                AVG(percentage_laid_off) AS avg_percentage_laid_off,\n","                COUNT(DISTINCT company) AS companies_affected\n","            FROM layoffs_final\n","            WHERE country IS NOT NULL AND country != ''\n","            GROUP BY country\n","            ORDER BY total_laid_off DESC\n","        \"\"\"))\n","\n","        # Step 6.9: Create time trend summary\n","        logger.info(\"Creating time trend summary...\")\n","        conn.execute(text(\"\"\"\n","            CREATE TABLE time_summary AS\n","            SELECT\n","                year,\n","                quarter,\n","                COUNT(*) AS layoff_events,\n","                SUM(total_laid_off) AS total_laid_off,\n","                AVG(percentage_laid_off) AS avg_percentage_laid_off,\n","                COUNT(DISTINCT company) AS companies_affected\n","            FROM layoffs_final\n","            GROUP BY year, quarter\n","            ORDER BY year, quarter\n","        \"\"\"))\n","\n","    # Get counts after each step for reporting\n","    with engine.connect() as conn:\n","        base_count = conn.execute(text(\"SELECT COUNT(*) FROM layoffs_base\")).scalar()\n","        deduped_count = conn.execute(text(\"SELECT COUNT(*) FROM layoffs_deduped\")).scalar()\n","        final_count = conn.execute(text(\"SELECT COUNT(*) FROM layoffs_final\")).scalar()\n","\n","    logger.info(f\"Initial cleaning: {raw_count} -> {base_count} rows\")\n","    logger.info(f\"After deduplication: {base_count} -> {deduped_count} rows\")\n","    logger.info(f\"Final dataset: {deduped_count} -> {final_count} rows\")\n","\n","except Exception as e:\n","    logger.error(f\"SQL transformation error: {e}\")\n","    raise\n","\n","# STEP 7: Export results using SQL to extract data\n","try:\n","    logger.info(\"Exporting final cleaned dataset...\")\n","\n","    # Get the main cleaned dataset\n","    df_final = pd.read_sql_query(\"SELECT * FROM layoffs_final\", engine)\n","\n","    # Convert date to proper datetime AND ensure it's timezone-unaware\n","    df_final['date'] = pd.to_datetime(df_final['date'], errors='coerce').dt.tz_localize(None)\n","\n","    # Get summary tables\n","    df_summary = pd.read_sql_query(\"SELECT * FROM layoffs_summary\", engine)\n","    df_industry = pd.read_sql_query(\"SELECT * FROM industry_summary\", engine)\n","    df_country = pd.read_sql_query(\"SELECT * FROM country_summary\", engine)\n","    df_time = pd.read_sql_query(\"SELECT * FROM time_summary\", engine)\n","\n","    # Make sure any date columns in summary tables are also timezone-unaware\n","    if 'earliest_date' in df_summary.columns:\n","        df_summary['earliest_date'] = pd.to_datetime(df_summary['earliest_date'], errors='coerce').dt.tz_localize(None)\n","    if 'latest_date' in df_summary.columns:\n","        df_summary['latest_date'] = pd.to_datetime(df_summary['latest_date'], errors='coerce').dt.tz_localize(None)\n","\n","    # Format summary table for display\n","    summary_stats = pd.DataFrame({\n","        'Metric': [\n","            'Total Companies',\n","            'Total Industries',\n","            'Total Countries',\n","            'Earliest Date',\n","            'Latest Date',\n","            'Total Employees Laid Off',\n","            'Average % Laid Off',\n","            'Max % Laid Off',\n","            'Total Funds Raised (Millions)',\n","            'Total Layoff Events',\n","            'Original Row Count',\n","            'Data Reduction %'\n","        ],\n","        'Value': [\n","            df_summary['total_companies'].iloc[0],\n","            df_summary['total_industries'].iloc[0],\n","            df_summary['total_countries'].iloc[0],\n","            df_summary['earliest_date'].iloc[0],\n","            df_summary['latest_date'].iloc[0],\n","            f\"{df_summary['total_employees_laid_off'].iloc[0]:,.0f}\",\n","            f\"{df_summary['avg_percentage_laid_off'].iloc[0]:.2f}%\",\n","            f\"{df_summary['max_percentage_laid_off'].iloc[0]:.2f}%\",\n","            f\"${df_summary['total_funds_raised'].iloc[0]:,.2f}\",\n","            df_summary['total_layoff_events'].iloc[0],\n","            df_summary['original_row_count'].iloc[0],\n","            f\"{(1 - df_summary['total_layoff_events'].iloc[0]/df_summary['original_row_count'].iloc[0])*100:.2f}%\"\n","        ]\n","    })\n","\n","    # Save to Excel with multiple sheets\n","    logger.info(f\"Saving to Excel: {output_excel}\")\n","    with pd.ExcelWriter(output_excel, engine='openpyxl') as writer:\n","        df_final.to_excel(writer, sheet_name='Cleaned_Data', index=False)\n","        summary_stats.to_excel(writer, sheet_name='Summary', index=False)\n","        df_industry.to_excel(writer, sheet_name='Industry_Analysis', index=False)\n","        df_country.to_excel(writer, sheet_name='Country_Analysis', index=False)\n","        df_time.to_excel(writer, sheet_name='Time_Analysis', index=False)\n","\n","    # Save to CSV for easier machine processing\n","    logger.info(f\"Saving to CSV: {output_csv}\")\n","    df_final.to_csv(output_csv, index=False)\n","\n","    logger.info(\"Files saved successfully\")\n","\n","except Exception as e:\n","    logger.error(f\"Export error: {e}\")\n","    raise\n","\n","# STEP 8: Create additional views for analysis (pure SQL approach)\n","try:\n","    logger.info(\"Creating analysis views...\")\n","    with engine.begin() as conn:\n","        # Top companies by layoff count\n","        conn.execute(text(\"\"\"\n","            CREATE VIEW top_layoff_companies AS\n","            SELECT\n","                company,\n","                SUM(total_laid_off) AS total_employees_laid_off,\n","                COUNT(*) AS layoff_events,\n","                AVG(percentage_laid_off) AS avg_percentage_laid_off\n","            FROM layoffs_final\n","            GROUP BY company\n","            ORDER BY total_employees_laid_off DESC\n","            LIMIT 10\n","        \"\"\"))\n","\n","        # Layoff trends by quarter\n","        conn.execute(text(\"\"\"\n","            CREATE VIEW quarterly_layoff_trends AS\n","            SELECT\n","                year,\n","                quarter,\n","                SUM(total_laid_off) AS total_laid_off,\n","                COUNT(*) AS layoff_events,\n","                COUNT(DISTINCT company) AS companies_affected\n","            FROM layoffs_final\n","            GROUP BY year, quarter\n","            ORDER BY year, quarter\n","        \"\"\"))\n","\n","        # Industry layoff patterns\n","        conn.execute(text(\"\"\"\n","            CREATE VIEW industry_layoff_patterns AS\n","            SELECT\n","                industry,\n","                AVG(percentage_laid_off) AS avg_percentage_laid_off,\n","                SUM(total_laid_off) AS total_laid_off,\n","                COUNT(DISTINCT company) AS companies_affected,\n","                MIN(date) AS first_layoff,\n","                MAX(date) AS latest_layoff\n","            FROM layoffs_final\n","            GROUP BY industry\n","            ORDER BY total_laid_off DESC\n","        \"\"\"))\n","except Exception as e:\n","    logger.error(f\"Analysis views error: {e}\")\n","    # Non-critical, continue execution\n","\n","# STEP 9: Print summary statistics\n","print(\"\\n\" + \"=\"*50)\n","print(f\" DATA CLEANING COMPLETE\")\n","print(\"=\"*50)\n","print(f\" Final dataset shape: {df_final.shape[0]} rows × {df_final.shape[1]} columns\")\n","print(f\" Date range: {pd.to_datetime(df_summary['earliest_date'].iloc[0]).strftime('%Y-%m-%d')} to {pd.to_datetime(df_summary['latest_date'].iloc[0]).strftime('%Y-%m-%d')}\")\n","print(f\" Companies analyzed: {df_summary['total_companies'].iloc[0]}\")\n","print(f\" Countries represented: {df_summary['total_countries'].iloc[0]}\")\n","print(f\" Total employees laid off: {df_summary['total_employees_laid_off'].iloc[0]:,.0f}\")\n","print(f\" Files saved:\")\n","print(f\"   - Excel: {os.path.basename(output_excel)}\")\n","print(f\"   - CSV: {os.path.basename(output_csv)}\")\n","print(\"=\"*50)\n","\n","# Return most interesting findings\n","top_industries = pd.read_sql_query(\"SELECT industry, total_laid_off FROM industry_summary ORDER BY total_laid_off DESC LIMIT 5\", engine)\n","print(\"\\n TOP 5 INDUSTRIES BY LAYOFFS:\")\n","for i, row in top_industries.iterrows():\n","    print(f\"   {i+1}. {row['industry']}: {row['total_laid_off']:,.0f} employees\")\n","\n","# Return the cleaned dataframe sample for inspection\n","df_final.head()"]}]}