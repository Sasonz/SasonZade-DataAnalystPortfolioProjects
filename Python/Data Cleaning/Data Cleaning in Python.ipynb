{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOJ6ko6WE6wEfvXhgs4Pec9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NuYxlcIP8moj","executionInfo":{"status":"ok","timestamp":1743775522072,"user_tz":-180,"elapsed":2643,"user":{"displayName":"Sason Zade","userId":"15696081868748133077"}},"outputId":"ce6b50d0-e92a-4d65-dd52-297002401051"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","✅ Cleaned dataset successfully saved to:\n","/content/drive/My Drive/Data_Analyst/Portfolio_Projects/Projects/Python/Calls_Dataset_After_Cleaning.xlsx\n","✅ Processing time: 2.6 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-8-653a3c4ebcb7>:212: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n","  df.fillna('', inplace=True)\n"]}],"source":["# ==============================================================================\n","# DATA CLEANING AND FORMATTING SCRIPT FOR CALL CENTER DATASET\n","# ==============================================================================\n","\"\"\"\n","This script processes a call center dataset by:\n","1. Cleaning and standardizing data\n","2. Applying specific formatting rules\n","3. Exporting to Excel with custom formatting\n","\"\"\"\n","\n","# ----------------------\n","# LIBRARY IMPORTS\n","# ----------------------\n","from google.colab import drive\n","import pandas as pd\n","import numpy as np\n","import re\n","import openpyxl\n","from openpyxl.styles import Border, Side, Font, Alignment\n","from datetime import datetime\n","import os\n","import logging\n","import time\n","\n","# ----------------------\n","# LOGGING CONFIGURATION\n","# ----------------------\n","# Set up logging to track script execution and capture any issues\n","logging.basicConfig(\n","    level=logging.INFO,\n","    format='%(asctime)s - %(levelname)s - %(message)s',\n","    datefmt='%Y-%m-%d %H:%M:%S'\n",")\n","logger = logging.getLogger(__name__)\n","\n","def main():\n","    \"\"\"\n","    Main function to orchestrate the data cleaning and formatting process\n","    \"\"\"\n","    start_time = time.time()\n","    logger.info(\"Starting data cleaning process\")\n","\n","    try:\n","        # Mount Google Drive\n","        mount_drive()\n","\n","        # Define file paths\n","        input_path, output_path = setup_file_paths()\n","\n","        # Load and process data\n","        df = load_data(input_path)\n","        df_clean = clean_and_transform_data(df)\n","\n","        # Export to Excel with formatting\n","        export_and_format_excel(df_clean, output_path)\n","\n","        execution_time = round(time.time() - start_time, 2)\n","        logger.info(f\"✅ Process completed successfully in {execution_time} seconds\")\n","        print(f\"✅ Cleaned dataset successfully saved to:\\n{output_path}\")\n","        print(f\"✅ Processing time: {execution_time} seconds\")\n","\n","    except Exception as e:\n","        logger.error(f\"Error in data processing: {str(e)}\")\n","        print(f\"❌ Error occurred: {str(e)}\")\n","\n","def mount_drive():\n","    \"\"\"Mount Google Drive for file access\"\"\"\n","    try:\n","        drive.mount('/content/drive')\n","        logger.info(\"Google Drive mounted successfully\")\n","    except Exception as e:\n","        logger.error(f\"Failed to mount Google Drive: {str(e)}\")\n","        raise Exception(\"Drive mounting failed. Please check your connection.\")\n","\n","def setup_file_paths():\n","    \"\"\"Define and validate input/output file paths\"\"\"\n","    base_path = '/content/drive/My Drive/Data_Analyst/Portfolio_Projects/Projects/Python'\n","    input_path = f\"{base_path}/Calls_Dataset_for_Data_Cleaning.xlsx\"\n","    output_path = f\"{base_path}/Calls_Dataset_After_Cleaning.xlsx\"\n","\n","    # Create backup of output file if it already exists\n","    if os.path.exists(output_path):\n","        backup_path = f\"{output_path.split('.')[0]}_backup_{int(time.time())}.xlsx\"\n","        try:\n","            os.rename(output_path, backup_path)\n","            logger.info(f\"Created backup of existing output file: {backup_path}\")\n","        except Exception as e:\n","            logger.warning(f\"Could not create backup: {str(e)}\")\n","\n","    # Verify input file exists\n","    if not os.path.exists(input_path):\n","        logger.error(f\"Input file not found: {input_path}\")\n","        raise FileNotFoundError(f\"Input file not found: {input_path}\")\n","\n","    return input_path, output_path\n","\n","def load_data(file_path):\n","    \"\"\"Load Excel data into DataFrame with error handling\"\"\"\n","    try:\n","        logger.info(f\"Loading data from {file_path}\")\n","        df = pd.read_excel(file_path)\n","        logger.info(f\"Successfully loaded {len(df)} rows and {len(df.columns)} columns\")\n","        return df\n","    except Exception as e:\n","        logger.error(f\"Failed to load data: {str(e)}\")\n","        raise Exception(f\"Data loading failed: {str(e)}\")\n","\n","def clean_and_transform_data(df):\n","    \"\"\"\n","    Clean and transform the dataset through multiple steps\n","    Returns a copy of the processed dataframe\n","    \"\"\"\n","    # Work with a copy to preserve original data\n","    df_clean = df.copy()\n","\n","    # Step 1: Clean column names\n","    df_clean = clean_column_names(df_clean)\n","\n","    # Step 2: Remove duplicates and irrelevant columns\n","    df_clean = remove_duplicates_and_irrelevant_columns(df_clean)\n","\n","    # Step 3: Handle missing values\n","    df_clean = handle_missing_values(df_clean)\n","\n","    # Step 4: Clean string columns\n","    df_clean = clean_string_columns(df_clean)\n","\n","    # Step 5: Clean phone numbers\n","    df_clean = clean_phone_numbers(df_clean)\n","\n","    # Step 6: Standardize Yes/No fields\n","    df_clean = standardize_yes_no_fields(df_clean)\n","\n","    # Step 7: Filter unwanted records\n","    df_clean = filter_unwanted_records(df_clean)\n","\n","    # Step 8: Process address fields\n","    df_clean = process_address_fields(df_clean)\n","\n","    # Step 9: Clean ZIP codes\n","    df_clean = clean_zip_codes(df_clean)\n","\n","    # Step 10: Convert Column H values\n","    df_clean = convert_column_h_values(df_clean)\n","\n","    # Step 11: Format date in Column B\n","    df_clean = format_date_column(df_clean)\n","\n","    # Step 12: Remove first column (as requested)\n","    if len(df_clean.columns) > 0:\n","        df_clean = df_clean.drop(columns=[df_clean.columns[0]])\n","        logger.info(\"Removed first column as requested\")\n","\n","    # Step 13: Reset index\n","    df_clean.reset_index(drop=True, inplace=True)\n","\n","    return df_clean\n","\n","def clean_column_names(df):\n","    \"\"\"Clean and standardize column names\"\"\"\n","    logger.info(\"Cleaning column names\")\n","    original_columns = df.columns.tolist()\n","\n","    df.columns = (\n","        df.columns\n","        .str.strip()\n","        .str.replace(\" \", \"_\")\n","        .str.replace(r\"[^\\w]\", \"\", regex=True)\n","    )\n","\n","    # Log column name changes\n","    for i, (old, new) in enumerate(zip(original_columns, df.columns)):\n","        if old != new:\n","            logger.info(f\"Column renamed: '{old}' -> '{new}'\")\n","\n","    return df\n","\n","def remove_duplicates_and_irrelevant_columns(df):\n","    \"\"\"Remove duplicate rows and unnecessary columns\"\"\"\n","    # Count duplicates before removal\n","    duplicate_count = df.duplicated().sum()\n","    if duplicate_count > 0:\n","        logger.info(f\"Removing {duplicate_count} duplicate rows\")\n","        df.drop_duplicates(inplace=True)\n","    else:\n","        logger.info(\"No duplicate rows found\")\n","\n","    # Remove irrelevant columns if they exist\n","    irrelevant_cols = ['Not_Useful_Column']\n","    columns_to_drop = [col for col in irrelevant_cols if col in df.columns]\n","    if columns_to_drop:\n","        logger.info(f\"Dropping irrelevant columns: {columns_to_drop}\")\n","        df.drop(columns=columns_to_drop, inplace=True)\n","\n","    return df\n","\n","def handle_missing_values(df):\n","    \"\"\"Handle missing values in the dataset\"\"\"\n","    # Count missing values before filling\n","    missing_counts = df.isna().sum()\n","    total_missing = missing_counts.sum()\n","\n","    if total_missing > 0:\n","        logger.info(f\"Replacing {total_missing} missing values with empty strings\")\n","        # Log columns with missing values\n","        for col, count in missing_counts.items():\n","            if count > 0:\n","                logger.info(f\"  - Column '{col}': {count} missing values\")\n","        df.fillna('', inplace=True)\n","    else:\n","        logger.info(\"No missing values found\")\n","\n","    return df\n","\n","def clean_string_columns(df):\n","    \"\"\"Clean and standardize string columns\"\"\"\n","    text_columns = df.select_dtypes(include='object').columns.tolist()\n","    logger.info(f\"Cleaning {len(text_columns)} text columns\")\n","\n","    for col in text_columns:\n","        df[col] = df[col].astype(str).str.strip()\n","\n","    # Special cleaning for Last_Name if it exists\n","    if 'Last_Name' in df.columns:\n","        logger.info(\"Applying special cleaning to Last_Name column\")\n","        df['Last_Name'] = df['Last_Name'].str.strip(\"123._/\").str.strip()\n","\n","    return df\n","\n","def clean_phone_numbers(df):\n","    \"\"\"Clean and standardize phone numbers\"\"\"\n","    if 'Phone_Number' in df.columns:\n","        logger.info(\"Cleaning Phone_Number column\")\n","\n","        # Store original values to count changes\n","        original_phones = df['Phone_Number'].copy()\n","\n","        df['Phone_Number'] = (\n","            df['Phone_Number']\n","            .str.replace(r'nan--|Na--', '', regex=True)\n","            .str.replace(r'[^0-9]', '', regex=True)\n","            .apply(lambda x: x if len(x) >= 10 else '')\n","        )\n","\n","        # Count how many numbers were cleaned\n","        cleaned_count = (original_phones != df['Phone_Number']).sum()\n","        logger.info(f\"Cleaned {cleaned_count} phone numbers\")\n","\n","        # Count how many were invalidated (set to empty)\n","        invalid_count = (df['Phone_Number'] == '').sum()\n","        if invalid_count > 0:\n","            logger.info(f\"Found {invalid_count} invalid phone numbers\")\n","\n","    return df\n","\n","def standardize_yes_no_fields(df):\n","    \"\"\"Standardize Yes/No fields to Y/N format\"\"\"\n","    if 'Do_Not_Contact' in df.columns:\n","        logger.info(\"Standardizing Do_Not_Contact field to Y/N format\")\n","\n","        original_values = df['Do_Not_Contact'].copy()\n","\n","        df['Do_Not_Contact'] = (\n","            df['Do_Not_Contact']\n","            .str.strip()\n","            .str.replace('Yes', 'Y', regex=False)\n","            .str.replace('No', 'N', regex=False)\n","            .str.upper()\n","        )\n","\n","        # Count changes\n","        changes_count = (original_values != df['Do_Not_Contact']).sum()\n","        logger.info(f\"Standardized {changes_count} values in Do_Not_Contact field\")\n","\n","    return df\n","\n","def filter_unwanted_records(df):\n","    \"\"\"Filter out unwanted records based on criteria\"\"\"\n","    original_row_count = len(df)\n","\n","    # Filter out Do Not Contact records\n","    if 'Do_Not_Contact' in df.columns:\n","        do_not_contact_count = (df['Do_Not_Contact'] == 'Y').sum()\n","        if do_not_contact_count > 0:\n","            logger.info(f\"Removing {do_not_contact_count} 'Do Not Contact' records\")\n","            df = df[df['Do_Not_Contact'] != 'Y']\n","\n","    # Filter out records with invalid phone numbers\n","    if 'Phone_Number' in df.columns:\n","        invalid_phone_count = (df['Phone_Number'] == '').sum()\n","        if invalid_phone_count > 0:\n","            logger.info(f\"Removing {invalid_phone_count} records with invalid phone numbers\")\n","            df = df[df['Phone_Number'] != '']\n","\n","    # Report total filtered records\n","    filtered_count = original_row_count - len(df)\n","    if filtered_count > 0:\n","        logger.info(f\"Total records filtered: {filtered_count} ({filtered_count/original_row_count:.1%} of data)\")\n","\n","    return df\n","\n","def process_address_fields(df):\n","    \"\"\"Process and split address fields into components\"\"\"\n","    if 'Address' in df.columns:\n","        logger.info(\"Processing Address field\")\n","\n","        # Count how many addresses contain commas (splittable)\n","        comma_count = df['Address'].str.contains(',').sum()\n","        logger.info(f\"Found {comma_count} addresses with comma separators\")\n","\n","        # Split address into components\n","        split_address = df['Address'].str.split(',', n=2, expand=True)\n","\n","        df['Street_Address'] = split_address[0].str.strip()\n","        logger.info(\"Created Street_Address column\")\n","\n","        if split_address.shape[1] > 1:\n","            df['State'] = split_address[1].str.strip()\n","            logger.info(\"Created State column\")\n","        else:\n","            df['State'] = ''\n","            logger.info(\"Created empty State column (no data available)\")\n","\n","        if split_address.shape[1] > 2:\n","            df['Zip_Code'] = split_address[2].str.strip()\n","            logger.info(\"Created Zip_Code column\")\n","        else:\n","            df['Zip_Code'] = ''\n","            logger.info(\"Created empty Zip_Code column (no data available)\")\n","\n","    return df\n","\n","def clean_zip_codes(df):\n","    \"\"\"Clean and standardize ZIP codes\"\"\"\n","    if 'Zip_Code' in df.columns:\n","        logger.info(\"Cleaning ZIP codes\")\n","\n","        original_zips = df['Zip_Code'].copy()\n","        df['Zip_Code'] = df['Zip_Code'].str.extract(r'(\\d{5})')\n","\n","        # Count valid and invalid ZIP codes\n","        valid_zip_count = df['Zip_Code'].notna().sum()\n","        invalid_zip_count = df['Zip_Code'].isna().sum()\n","\n","        logger.info(f\"Extracted {valid_zip_count} valid 5-digit ZIP codes\")\n","        if invalid_zip_count > 0:\n","            logger.info(f\"Found {invalid_zip_count} invalid ZIP codes\")\n","\n","    return df\n","\n","def convert_column_h_values(df):\n","    \"\"\"Convert values in column H from 'Yes' to 'Y' and 'No' to 'N'\"\"\"\n","    # Check if there are enough columns to have an H column\n","    if len(df.columns) >= 7:  # Column H would be at index 7 (0-based)\n","        col_h = df.columns[7]\n","        logger.info(f\"Converting Yes/No values in column '{col_h}' (Column H)\")\n","\n","        original_values = df[col_h].copy()\n","\n","        df[col_h] = (\n","            df[col_h]\n","            .astype(str)\n","            .str.strip()\n","            .str.replace('Yes', 'Y', regex=False)\n","            .str.replace('No', 'N', regex=False)\n","        )\n","\n","        # Count changes\n","        changes_count = (original_values != df[col_h]).sum()\n","        logger.info(f\"Converted {changes_count} values in column '{col_h}'\")\n","    else:\n","        logger.warning(\"Column H not found - dataset doesn't have enough columns\")\n","\n","    return df\n","\n","def format_date_column(df):\n","    \"\"\"Format date column (Column B) to remove time component\"\"\"\n","    if len(df.columns) > 0:\n","        col_b = df.columns[0]  # First column\n","        logger.info(f\"Processing date formatting in column '{col_b}' (Column B)\")\n","\n","        # Check if column contains datetime values\n","        if pd.api.types.is_datetime64_any_dtype(df[col_b]):\n","            logger.info(f\"Converting datetime values in '{col_b}' to date-only format\")\n","            df[col_b] = df[col_b].dt.date\n","        elif df[col_b].dtype == 'object':\n","            # Try to convert string dates to proper dates\n","            try:\n","                logger.info(f\"Attempting to convert string values in '{col_b}' to dates\")\n","                df[col_b] = pd.to_datetime(df[col_b]).dt.date\n","                logger.info(\"Conversion successful\")\n","            except Exception as e:\n","                logger.warning(f\"Could not convert column '{col_b}' to date: {str(e)}\")\n","\n","    return df\n","\n","def export_and_format_excel(df, output_path):\n","    \"\"\"Export data to Excel and apply formatting\"\"\"\n","    try:\n","        logger.info(f\"Exporting data to {output_path}\")\n","\n","        # First, export with pandas to create the Excel file\n","        df.to_excel(output_path, index=True)\n","        logger.info(f\"Basic Excel export completed: {len(df)} rows, {len(df.columns)} columns\")\n","\n","        # Now open with openpyxl to apply formatting\n","        logger.info(\"Applying Excel formatting\")\n","        wb = openpyxl.load_workbook(output_path)\n","        ws = wb.active\n","\n","        # Define styles\n","        thin_border = Border(\n","            left=Side(style='thin'),\n","            right=Side(style='thin'),\n","            top=Side(style='thin'),\n","            bottom=Side(style='thin')\n","        )\n","        bold_font = Font(bold=True)\n","        regular_font = Font(bold=False)\n","        centered_align = Alignment(horizontal='center')\n","\n","        # Apply formatting to all cells\n","        logger.info(\"Applying borders and font formatting\")\n","        max_row = len(df) + 1  # +1 for header row\n","        max_col = len(df.columns) + 1  # +1 for index column\n","\n","        for row_idx, row in enumerate(ws.iter_rows(min_row=1, max_row=max_row, min_col=1, max_col=max_col)):\n","            for cell in row:\n","                # Apply border to all cells\n","                cell.border = thin_border\n","\n","                # Apply bold font only to header row\n","                if row_idx == 0:  # First row (headers)\n","                    cell.font = bold_font\n","                    cell.alignment = centered_align\n","                else:  # Data rows\n","                    cell.font = regular_font\n","\n","        # Rename index header to \"Index\"\n","        logger.info(\"Setting 'Index' label in cell A1\")\n","        ws['A1'] = 'Index'\n","\n","        # Apply date formatting to column B\n","        if max_col > 1:  # Make sure we have at least 2 columns\n","            logger.info(\"Setting date format in column B\")\n","            date_column = ws['B']\n","            for cell in date_column[1:]:  # Skip header\n","                if isinstance(cell.value, (datetime, str)):\n","                    try:\n","                        cell.number_format = 'YYYY-MM-DD'\n","                    except Exception as e:\n","                        logger.warning(f\"Could not set date format: {str(e)}\")\n","\n","        # Auto-adjust column widths for better visibility\n","        logger.info(\"Auto-adjusting column widths\")\n","        for col in ws.columns:\n","            max_length = 0\n","            column = col[0].column_letter  # Get column letter\n","\n","            for cell in col:\n","                try:\n","                    if len(str(cell.value)) > max_length:\n","                        max_length = len(str(cell.value))\n","                except:\n","                    pass\n","\n","            adjusted_width = max_length + 2\n","            ws.column_dimensions[column].width = min(adjusted_width, 50)  # Cap width at 50\n","\n","        # Save the workbook\n","        wb.save(output_path)\n","        logger.info(f\"Excel formatting completed and saved to {output_path}\")\n","\n","    except Exception as e:\n","        logger.error(f\"Error during Excel export/formatting: {str(e)}\")\n","        raise Exception(f\"Failed to format Excel: {str(e)}\")\n","\n","# Execute main function when script is run directly\n","if __name__ == \"__main__\":\n","    main()"]}]}